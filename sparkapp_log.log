[INFO ]2017-01-06 16:07:46  [main:com.pujjr.antifraud.com.SocketServer.run(SocketServer.java:47):1] - 服务端启动成功，监听端口：5000
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.SocketServerHandler.channelRead(SocketServerHandler.java:55):11125] - NettyServerHandler 接受客户端报文:{"tranCode":"00001","appId":"D4021611030272N1"}
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortReceiverImpl.doReceive(SynShortReceiverImpl.java:28):11133] - receive from client：{"tranCode":"00001","appId":"D4021611030272N1"}
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortReceiverImpl.doReceive(SynShortReceiverImpl.java:36):11207] - tranCode：00001
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:232):11209] - Rdd服务
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):11387] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):11424] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):11424] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):11424] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11462] - Running Spark version 2.0.0
[WARN ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):11767] - 
SPARK_CLASSPATH was detected (set to 'E:\spark-2.0.0-bin-hadoop2.7\jars').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):11768] - Setting 'spark.executor.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[WARN ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66):11768] - Setting 'spark.driver.extraClassPath' to 'E:\spark-2.0.0-bin-hadoop2.7\jars' as a work-around.
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11788] - Changing view acls to: pujjr
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11789] - Changing modify acls to: pujjr
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11789] - Changing view acls groups to: 
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11791] - Changing modify acls groups to: 
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11791] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pujjr); groups with view permissions: Set(); users  with modify permissions: Set(pujjr); groups with modify permissions: Set()
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11886] - Successfully started service 'sparkDriver' on port 61096.
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11902] - Registering MapOutputTracker
[INFO ]2017-01-06 16:07:57  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):11946] - Registering BlockManagerMaster
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12028] - Created local directory at C:\Users\pujjr\AppData\Local\Temp\blockmgr-601b67e4-1867-441c-8ba5-f87a7f41e3c6
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12044] - MemoryStore started with capacity 906.0 MB
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12084] - Registering OutputCommitCoordinator
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.util.log.Log.initialized(Log.java:186):12150] - Logging initialized @12840ms
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.Server.doStart(Server.java:327):12223] - jetty-9.2.z-SNAPSHOT
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12238] - Started o.s.j.s.ServletContextHandler@80ef9ee{/jobs,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12238] - Started o.s.j.s.ServletContextHandler@4a73c3bc{/jobs/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12239] - Started o.s.j.s.ServletContextHandler@61b7b384{/jobs/job,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12240] - Started o.s.j.s.ServletContextHandler@321fa1a8{/jobs/job/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12240] - Started o.s.j.s.ServletContextHandler@4da1ff8c{/stages,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12240] - Started o.s.j.s.ServletContextHandler@199baba7{/stages/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12241] - Started o.s.j.s.ServletContextHandler@45ec0083{/stages/stage,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12241] - Started o.s.j.s.ServletContextHandler@ab1eb77{/stages/stage/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12241] - Started o.s.j.s.ServletContextHandler@482e3832{/stages/pool,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12242] - Started o.s.j.s.ServletContextHandler@cac6403{/stages/pool/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12242] - Started o.s.j.s.ServletContextHandler@29e1950d{/storage,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12242] - Started o.s.j.s.ServletContextHandler@2c0e3915{/storage/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12243] - Started o.s.j.s.ServletContextHandler@15d86b0e{/storage/rdd,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12243] - Started o.s.j.s.ServletContextHandler@7a3b89ca{/storage/rdd/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12243] - Started o.s.j.s.ServletContextHandler@5fd7227d{/environment,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12244] - Started o.s.j.s.ServletContextHandler@2cc7e03{/environment/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12244] - Started o.s.j.s.ServletContextHandler@541af54f{/executors,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12244] - Started o.s.j.s.ServletContextHandler@724943df{/executors/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12244] - Started o.s.j.s.ServletContextHandler@146b5321{/executors/threadDump,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12245] - Started o.s.j.s.ServletContextHandler@75b60bc9{/executors/threadDump/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12251] - Started o.s.j.s.ServletContextHandler@760528bd{/static,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12251] - Started o.s.j.s.ServletContextHandler@4eeada19{/,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12252] - Started o.s.j.s.ServletContextHandler@567abe{/api,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12252] - Started o.s.j.s.ServletContextHandler@45fbd13e{/stages/stage/kill,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:266):12261] - Started ServerConnector@1aa26462{HTTP/1.1}{0.0.0.0:4040}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.Server.doStart(Server.java:379):12261] - Started @12953ms
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12262] - Successfully started service 'SparkUI' on port 4040.
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12264] - Bound SparkUI to 0.0.0.0, and started at http://172.18.10.41:4040
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12353] - Starting executor ID driver on host localhost
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12385] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61105.
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12386] - Server created on 172.18.10.41:61105
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12387] - Registering BlockManager BlockManagerId(driver, 172.18.10.41, 61105)
[INFO ]2017-01-06 16:07:58  [dispatcher-event-loop-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12390] - Registering block manager 172.18.10.41:61105 with 906.0 MB RAM, BlockManagerId(driver, 172.18.10.41, 61105)
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12392] - Registered BlockManager BlockManagerId(driver, 172.18.10.41, 61105)
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12506] - Started o.s.j.s.ServletContextHandler@7ae067ea{/metrics/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12556] - Started o.s.j.s.ServletContextHandler@4aebca75{/SQL,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12557] - Started o.s.j.s.ServletContextHandler@7b8a17a7{/SQL/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12557] - Started o.s.j.s.ServletContextHandler@31d8f1fe{/SQL/execution,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12558] - Started o.s.j.s.ServletContextHandler@1c242c04{/SQL/execution/json,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:744):12560] - Started o.s.j.s.ServletContextHandler@77e375c1{/static/sql,null,AVAILABLE}
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):12573] - Warehouse path is '/path/to/my/'.
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):12574] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):12575] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):12575] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:07:58  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):12575] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:01  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15093] - Code generated in 156.885907 ms
[INFO ]2017-01-06 16:08:01  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15177] - Starting job: count at RddServiceImpl.java:243
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15191] - Got job 0 (count at RddServiceImpl.java:243) with 1 output partitions
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15191] - Final stage: ResultStage 0 (count at RddServiceImpl.java:243)
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15192] - Parents of final stage: List()
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15193] - Missing parents: List()
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15197] - Submitting ResultStage 0 (MapPartitionsRDD[4] at filter at RddServiceImpl.java:241), which has no missing parents
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15299] - Block broadcast_0 stored as values in memory (estimated size 15.5 KB, free 906.0 MB)
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15328] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KB, free 906.0 MB)
[INFO ]2017-01-06 16:08:01  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15330] - Added broadcast_0_piece0 in memory on 172.18.10.41:61105 (size: 6.8 KB, free: 906.0 MB)
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15332] - Created broadcast 0 from broadcast at DAGScheduler.scala:1012
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15336] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at filter at RddServiceImpl.java:241)
[INFO ]2017-01-06 16:08:01  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15338] - Adding task set 0.0 with 1 tasks
[INFO ]2017-01-06 16:08:01  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15372] - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2017-01-06 16:08:01  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):15378] - Running task 0.0 in stage 0.0 (TID 0)
[INFO ]2017-01-06 16:08:03  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):17305] - Code generated in 19.998184 ms
[INFO ]2017-01-06 16:08:07  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):21152] - closed connection
[INFO ]2017-01-06 16:08:07  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):21163] - Finished task 0.0 in stage 0.0 (TID 0). 1341 bytes result sent to driver
[INFO ]2017-01-06 16:08:07  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):21169] - Finished task 0.0 in stage 0.0 (TID 0) in 5812 ms on localhost (1/1)
[INFO ]2017-01-06 16:08:07  [task-result-getter-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):21170] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO ]2017-01-06 16:08:07  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):21173] - ResultStage 0 (count at RddServiceImpl.java:243) finished in 5.825 s
[INFO ]2017-01-06 16:08:07  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):21177] - Job 0 finished: count at RddServiceImpl.java:243, took 5.999181 s
[INFO ]2017-01-06 16:08:07  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:244):21179] - RDD处理结束
[INFO ]2017-01-06 16:08:07  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:247):21179] - 执行完成，耗时：9
[INFO ]2017-01-06 16:08:07  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortSenderImpl.doSend(SynShortSenderImpl.java:33):21180] - send to client:00020海量数据表格读取测试
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.SocketServerHandler.channelRead(SocketServerHandler.java:55):26875] - NettyServerHandler 接受客户端报文:{"tranCode":"00001","appId":"D4021611030272N1"}
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortReceiverImpl.doReceive(SynShortReceiverImpl.java:28):26876] - receive from client：{"tranCode":"00001","appId":"D4021611030272N1"}
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortReceiverImpl.doReceive(SynShortReceiverImpl.java:36):26876] - tranCode：00001
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:232):26876] - Rdd服务
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):26894] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):26895] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):26896] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):26896] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:12  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26968] - Starting job: count at RddServiceImpl.java:243
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26969] - Got job 1 (count at RddServiceImpl.java:243) with 1 output partitions
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26969] - Final stage: ResultStage 1 (count at RddServiceImpl.java:243)
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26969] - Parents of final stage: List()
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26969] - Missing parents: List()
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26970] - Submitting ResultStage 1 (MapPartitionsRDD[9] at filter at RddServiceImpl.java:241), which has no missing parents
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26976] - Block broadcast_1 stored as values in memory (estimated size 15.5 KB, free 906.0 MB)
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26978] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 906.0 MB)
[INFO ]2017-01-06 16:08:12  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26979] - Added broadcast_1_piece0 in memory on 172.18.10.41:61105 (size: 6.8 KB, free: 906.0 MB)
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26980] - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26980] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at filter at RddServiceImpl.java:241)
[INFO ]2017-01-06 16:08:12  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26980] - Adding task set 1.0 with 1 tasks
[INFO ]2017-01-06 16:08:12  [dispatcher-event-loop-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26982] - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2017-01-06 16:08:12  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):26983] - Running task 0.0 in stage 1.0 (TID 1)
[INFO ]2017-01-06 16:08:16  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):30747] - Removed broadcast_0_piece0 on 172.18.10.41:61105 in memory (size: 6.8 KB, free: 906.0 MB)
[INFO ]2017-01-06 16:08:17  [Spark Context Cleaner:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):31195] - Cleaned accumulator 1
[INFO ]2017-01-06 16:08:17  [Spark Context Cleaner:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):31199] - Cleaned accumulator 0
[INFO ]2017-01-06 16:08:18  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):32194] - closed connection
[INFO ]2017-01-06 16:08:18  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):32195] - Finished task 0.0 in stage 1.0 (TID 1). 1254 bytes result sent to driver
[INFO ]2017-01-06 16:08:18  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):32196] - Finished task 0.0 in stage 1.0 (TID 1) in 5215 ms on localhost (1/1)
[INFO ]2017-01-06 16:08:18  [task-result-getter-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):32196] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO ]2017-01-06 16:08:18  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):32196] - ResultStage 1 (count at RddServiceImpl.java:243) finished in 5.215 s
[INFO ]2017-01-06 16:08:18  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):32197] - Job 1 finished: count at RddServiceImpl.java:243, took 5.228323 s
[INFO ]2017-01-06 16:08:18  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:244):32198] - RDD处理结束
[INFO ]2017-01-06 16:08:18  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:247):32198] - 执行完成，耗时：5
[INFO ]2017-01-06 16:08:18  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortSenderImpl.doSend(SynShortSenderImpl.java:33):32198] - send to client:00020海量数据表格读取测试
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.SocketServerHandler.channelRead(SocketServerHandler.java:55):37837] - NettyServerHandler 接受客户端报文:{"tranCode":"00001","appId":"D4021611030272N1"}
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortReceiverImpl.doReceive(SynShortReceiverImpl.java:28):37838] - receive from client：{"tranCode":"00001","appId":"D4021611030272N1"}
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortReceiverImpl.doReceive(SynShortReceiverImpl.java:36):37839] - tranCode：00001
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:232):37839] - Rdd服务
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):37839] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):37840] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):37841] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:com.pujjr.antifraud.util.Utils.getProperty(Utils.java:35):37841] - path:/E:/Workspaces/EclipseMars/pjsp/pjsp/target/classes/
[INFO ]2017-01-06 16:08:23  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37904] - Starting job: count at RddServiceImpl.java:243
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37905] - Got job 2 (count at RddServiceImpl.java:243) with 1 output partitions
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37906] - Final stage: ResultStage 2 (count at RddServiceImpl.java:243)
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37906] - Parents of final stage: List()
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37906] - Missing parents: List()
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37906] - Submitting ResultStage 2 (MapPartitionsRDD[14] at filter at RddServiceImpl.java:241), which has no missing parents
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37912] - Block broadcast_2 stored as values in memory (estimated size 15.5 KB, free 906.0 MB)
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37976] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KB, free 906.0 MB)
[INFO ]2017-01-06 16:08:23  [dispatcher-event-loop-3:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37979] - Added broadcast_2_piece0 in memory on 172.18.10.41:61105 (size: 6.8 KB, free: 906.0 MB)
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37980] - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37981] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at filter at RddServiceImpl.java:241)
[INFO ]2017-01-06 16:08:23  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37982] - Adding task set 2.0 with 1 tasks
[INFO ]2017-01-06 16:08:23  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37989] - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5084 bytes)
[INFO ]2017-01-06 16:08:23  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):37991] - Running task 0.0 in stage 2.0 (TID 2)
[INFO ]2017-01-06 16:08:26  [dispatcher-event-loop-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):40577] - Removed broadcast_1_piece0 on 172.18.10.41:61105 in memory (size: 6.8 KB, free: 906.0 MB)
[INFO ]2017-01-06 16:08:26  [Spark Context Cleaner:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):40578] - Cleaned accumulator 47
[INFO ]2017-01-06 16:08:26  [Spark Context Cleaner:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):40579] - Cleaned accumulator 46
[INFO ]2017-01-06 16:08:29  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):43043] - closed connection
[INFO ]2017-01-06 16:08:29  [Executor task launch worker-0:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):43044] - Finished task 0.0 in stage 2.0 (TID 2). 1254 bytes result sent to driver
[INFO ]2017-01-06 16:08:29  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):43045] - Finished task 0.0 in stage 2.0 (TID 2) in 5060 ms on localhost (1/1)
[INFO ]2017-01-06 16:08:29  [task-result-getter-2:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):43045] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO ]2017-01-06 16:08:29  [dag-scheduler-event-loop:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):43045] - ResultStage 2 (count at RddServiceImpl.java:243) finished in 5.061 s
[INFO ]2017-01-06 16:08:29  [nioEventLoopGroup-3-1:org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54):43046] - Job 2 finished: count at RddServiceImpl.java:243, took 5.140926 s
[INFO ]2017-01-06 16:08:29  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:244):43046] - RDD处理结束
[INFO ]2017-01-06 16:08:29  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.RddServiceImpl.selectBigDataTest(RddServiceImpl.java:247):43046] - 执行完成，耗时：5
[INFO ]2017-01-06 16:08:29  [nioEventLoopGroup-3-1:com.pujjr.antifraud.com.service.impl.SynShortSenderImpl.doSend(SynShortSenderImpl.java:33):43047] - send to client:00020海量数据表格读取测试
